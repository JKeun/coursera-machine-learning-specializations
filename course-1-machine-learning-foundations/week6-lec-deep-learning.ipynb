{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning very non-linear features with neural networks\n",
    "- Linear classifiers\n",
    " - $\\text{Score(x)} = w_0 + w_1x_1 + w_2x_2 + \\cdots + w_dx_d$\n",
    "   - $\\text{Score(x)} > 0$\n",
    "   - $\\text{Score(x)} < 0$\n",
    "- Graph representation of classifier: useful for defining neural networks\n",
    "<img src=\"./figures/w5-f1.png\" width=400>\n",
    "\n",
    "- What can a linear classifier represent?\n",
    "<img src=\"./figures/w5-f2.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What can't a simple linear classifier represent?\n",
    " - Impossible with only one simple linear classifier\n",
    "<img src=\"./figures/w5-f3.png\" width=400>\n",
    "\n",
    "- Solving the XOR problem: Adding a layer\n",
    "<img src=\"./figures/w5-f4.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x1 AND NOT x2`\n",
    "```\n",
    "x1 |  x2 | z1\n",
    "0  |  0  | 0\n",
    "1  |  0  | 1\n",
    "0  |  1  | 0\n",
    "1  |  1  | 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NOT x1 AND x2`\n",
    "```\n",
    "x1 |  x2 | z2\n",
    "0  |  0  | 0\n",
    "1  |  0  | 0\n",
    "0  |  1  | 1\n",
    "1  |  1  | 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`z1 OR z2`\n",
    "```\n",
    "z1 |  z2 | y\n",
    "0  |  0  | 0\n",
    "1  |  0  | 1\n",
    "0  |  1  | 1\n",
    "0  |  0  | 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**quiz hints:**\n",
    "- https://www.coursera.org/learn/ml-foundations/discussions/weeks/6/threads/AAIUurrtEeWGphLhfbPAyQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A neural network\n",
    "- Layers and layers and layers of linear models and non-linear transformations\n",
    "- Around for about 50 years\n",
    " - Fell in \"disfavor\" in 90s\n",
    "- In last few years, big resurgence\n",
    " - Impressive accuracy on several benchmark problems\n",
    " - Powered by huge datasets, GPUs, & modeling/learning alg improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of deep learning to computer vision\n",
    "- Image features\n",
    " - Features = local detectors\n",
    "   - Combined to make prediction\n",
    "   - (in reality, features are more low-level)\n",
    "   - ex. Nose detector, Eye detector, Mouth detector, ... =-> Face\n",
    "- Typical local detectors look for locally \"interesting points\" in image\n",
    " - Image features: collections of locally intersting points\n",
    "   - Combined to build classifiers\n",
    " - Many hand create freatures exist for finding interest points\n",
    " - Standard image classification approach\n",
    "   - Input -> Extract features ( Hand-created features ) -> Use imple classifier (e.g., logistic regression, SVMs) -> Face?\n",
    " - but very painful for design..\n",
    "- **Deep learning: implicitly learns features**\n",
    "  - Input -> Layer 1 -> Layer 2 -> Layer 3 -> Prediction\n",
    "  - Each Layer learn interest points to detect\n",
    "- **Deep learning performance**\n",
    " - Sample results using deep nerual networks\n",
    "   - German traffic sign recognition benchmark ( 99.5% accuracy )\n",
    "   - House number recognition ( 97.8% accuracy )\n",
    " - ImageNet 2012 competition: 1.2M training images, 1000 categories\n",
    "   - SuperVision ( deep-learning classifier ) won\n",
    "   - 8 layers, 60M parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges of deep learning\n",
    "- Pros\n",
    " - Enables learning of features rather than hand tuning\n",
    " - Impressive performance gains\n",
    "   - Computer vision\n",
    "   - Speech recognition\n",
    "   - Some text analysis\n",
    " - Potential for more impact\n",
    "- Deep learning workflow\n",
    " - Lots of labeled data\n",
    "   - Training set -> Learn deep neural net\n",
    "   - Validation set -> Validate -> Adjust parameters, network architecture, ...\n",
    "- Many tricks needed to work well..\n",
    "  - Defferenct types of layers, connections, ... needed for high accuracy\n",
    "- Cons\n",
    " - Requires a lot of data for high accuracy\n",
    " - Computationally really expensive\n",
    " - Extremely hard to tune\n",
    "   - Choice of architecture\n",
    "   - Parameter types\n",
    "   - Hyperparameters\n",
    "   - Learning algorithm\n",
    "   - ...\n",
    "- Computational cost + so many choices = incredibly hard to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep feautres: Deep learning + Transfer learning\n",
    "- Can we learn features from data, even when we don't have data or time?\n",
    "- **Transfer learning: Use data from one task to help learn on another**\n",
    " - Old idea, explored for deep learning by Donahue\n",
    " - Flow:\n",
    "   - Lots of data(cat, dog) -> Learn neural net -> Great accuracy on cat v. dog\n",
    "   - Some data(many items) -> Neural net as feature extractor + Simple classifier -> Great accuracy on 101 categories\n",
    "   \n",
    "**What's learned in a neural net**\n",
    "- Neural net trained for Task 1: cat vs. dog\n",
    "  - input -> `Layer 1` -> `Layer 2` -> `Layer ...` -> `End part layers` -> output\n",
    "  - `Layer 1 ~ Layer ...` : More generic Can be used as feature extractor\n",
    "  - `End part layers` : Very specific to Task 1 Should be ignored for other tasks\n",
    "- For Task 2, predicting 101 categories, learn only end part of neural net\n",
    "  - `Layer 1 ~ Layer ...`: Keep weights fixed!\n",
    "  - `End of part` : Use simple clasisfier(e.g., logistic regression, SVMs, nearest neighbor, ...) \n",
    "  \n",
    "**Transfer learning with deep features workflow**\n",
    "- Some labeled data -> Extract features with neural net trained on different task\n",
    " - Training set -> Learn simple classifier\n",
    " - Validation set -> Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning ML block diagram\n",
    "- `Training Data`( images, labels ) -> `Featrue extraction` -> $x$ ( deep features )\n",
    "- $x$ -> `ML model(logistic regression)` ( $\\hat{w}$: weights of features) -> $\\hat{y}$ ( predicted labels )\n",
    "- `y` is true label\n",
    "- `Quality metric` -> `ML algorithm` -> classification accuracy -> $\\hat{w}$\n",
    " - loop, updating for maximize accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
