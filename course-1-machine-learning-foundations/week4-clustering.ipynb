{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word count representation for measuring similarity\n",
    "- Bag of words model\n",
    " - Ignore order of words\n",
    " - Count # of instances of each word in vocabulary\n",
    " - ex\n",
    "   - \"Carlos calls the sport futbol. Emily calls the sport soccer.\"\n",
    "   - `1222111`\n",
    "   - `Carlos / the / calls / sport / futbol / soccer / Emily`\n",
    " \n",
    "- Measuring similarity\n",
    " - dot product\n",
    "   - `15300100`\n",
    "   - `32001000`\n",
    "   - similarity : $1 \\cdot 3 + 5 \\cdot 2 = 13$\n",
    "   \n",
    "- Issues with word counts -> Doc length\n",
    "- Solution -> normalize\n",
    " - compute each **norm vector**\n",
    "   - `15300100` -> $\\sqrt{1^2 + 5^2 + 3^2 + 1^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prioritizing important words with tf-idf\n",
    "- Issues with word counts -> Rare words\n",
    " - Common words in doc: \"the\", \"player\", field\", \"goal\"\n",
    " - Dominate rare words like: \"futbol\", \"Messi\"\n",
    "\n",
    "- Document frequency\n",
    " - What characterizes a *rare word?*\n",
    "   - Appears *infrequently* in the corpus\n",
    " - Emphasize words appearing in *few docs*\n",
    "   - Equivalently, discount word $w$ based on *# of docs containing $w$ in corpus*\n",
    " \n",
    "- Important words\n",
    " - Do we want only rare words to dominate?\n",
    " - What characterizes as *important word?*\n",
    "   - Appears frequently in document ( *common locally* )\n",
    "   - Appears rarely in corpus ( *rare globally* )\n",
    " - Trade off between **local frequency** and **global rarity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating tf-idf vectors\n",
    "- TF-IDF ( Term frequency - inverse document frequency )\n",
    " - Term frequency\n",
    "   - same as word count\n",
    " - Inverse document frequency\n",
    "   - $log{ \\frac{\\text{# docs}}{1 + \\text{# docs using word}} }$\n",
    "   \n",
    "- IDF\n",
    " - if. word in many docs -> $log{ \\frac{\\text{large #}}{1 + \\text{large #}} } = log{1} = 0$\n",
    " - if. rare word -> $log{ \\frac{\\text{large #}}{1 + \\text{small #}} } = \\text{large #}$\n",
    "\n",
    "- example\n",
    " - Term frequency\n",
    "   - `the / Messi`\n",
    "   - `1000 / 5`\n",
    " - Inverse document frequency\n",
    "   - \"the\" -> $log{\\frac{64}{1+63}} = 0$\n",
    "   - \"Messi\" -> $log{\\frac{64}{1+8}} = log{16} = 4$\n",
    "   - `the / Messi`\n",
    "   - `0 / 4`\n",
    " - TF-IDF\n",
    "   - elementwise multiply: `0 / 20`\n",
    "   - weight of \"the\" is going to be smalle\n",
    "   - weight of \"Messi\" is going to be large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving similar documents\n",
    "- Nearest neighbor search\n",
    " - Query article\n",
    " - Corpus\n",
    " - **Specify**: Distance metric\n",
    " - **Output**: Set of most similar articles\n",
    " \n",
    "- 1 - Nearest neighbor\n",
    " - Input: Query article `A`\n",
    " - Output: **Most** similar article `Most`\n",
    " - Algorithm:\n",
    "   - Search over each article `B` in corpus\n",
    "     - Compute **s = similarity(`A`, `B`)**, also `C`, `D`, ...\n",
    "     - If **S > Best_s**, record `Most` = `D` and set **Best_s = s**\n",
    "   - Return \n",
    "   \n",
    "- k - Nearest neighbor\n",
    " - Input: Query article `A`\n",
    " - Output: **List of k** similar articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering documents overview\n",
    "- Structure documents by topic\n",
    " - Discover groups (clusters) of related articles: Sports, World news..\n",
    "- What if some of the labels are known?\n",
    " - Training set of labeled docs\n",
    "- Multiclass classification problem\n",
    " - supervised learning\n",
    " \n",
    "### Clustering documents: An unsupervised learning task\n",
    "- Clustering\n",
    " - No labels provided\n",
    " - Want to uncover cluster structure\n",
    " - **Input**: docs as vectors\n",
    " - **Output**: cluster labels\n",
    " - An **unsupervised learning** task\n",
    "\n",
    "- What defines a cluster?\n",
    " - Cluster defined by **center & shape/spread**\n",
    " - Assign observation (*doc*) to cluster (*topic label*)\n",
    "   - Score under cluster is higher than others\n",
    "   - Often, just more similar to assigned cluster center than other cluster centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means\n",
    "- Assume\n",
    " - Similarity metric = **distance to cluster center** (smaller better)\n",
    "- algorithm\n",
    " 1. Initialize cluster centers (random choice)\n",
    " 2. Assign observations to closest cluster center\n",
    "   - Voronoi tessellation\n",
    " 3. Revise cluster centers as mean of assigned observations\n",
    " 4. Repeat 1. + 2. until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other examples\n",
    "- Clustering images\n",
    " - For search, group as: Ocean, Pinnk flower, Dog, ...\n",
    "- Grouping patients by medical condition\n",
    " - Better characterize subpopulations and diseases\n",
    "- Products on Amazon\n",
    " - Discover product categories from purchase histories\n",
    " - Recommender System\n",
    " - Or discovering groups of users\n",
    "- Structuring web search results\n",
    " - Search terms can have multiple meanings\n",
    "- Discovering similar neighborhoods\n",
    " - Task 1: Estimate price at a small regional level\n",
    "  - Challenge: Only a few(or no!) sales in each region per month\n",
    "  - Solution: Cluster regions with similar trends and share information within a cluster\n",
    " - Task 2: Forecast violent crimes to better task police\n",
    "  - Again, cluster regions and share information!\n",
    "  - Leads to improved predictions compared to examining each region independently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering and similarity ML block diagram\n",
    "- `Training Data`( doc id, doc text table ) -> `Featrue extraction` -> $x$ ( tf-idf )\n",
    "- $x$ -> `ML model(clustering)` ( $\\hat{w}$: cluster centers ) -> $\\hat{y}$ ( estimated cluster label )\n",
    "- real `y` is not here (unsupervised)\n",
    "- `Quality metric` -> `ML algorithm (k-means)` -> distances( $x, \\hat{w}$ ) -> $\\hat{w}$\n",
    " - loop, updating for minimizing sum of distances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
