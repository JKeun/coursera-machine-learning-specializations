{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Production?\n",
    "- **Deployment**: Serving live predictions\n",
    "- **Evaluation**: Measuring quality of deployed models\n",
    "- **Management**: Choosing between deployed models\n",
    "- **Monitoring**: Tracking model quality & operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment System\n",
    "- `Historical Data` -> `Model` : **Batch training**\n",
    "- `Live Data` -> `Model` <-> `Info & recommendations` : **Real-time predictions**\n",
    "- **Feedback** from Real-time predictions to Batch training\n",
    "\n",
    "**After deployment**\n",
    "- Evaluation & Management & Monitoring\n",
    "- Evaluate and track metrics over time\n",
    "- React to feedback from deployed odels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Management: Learning new, alternative models\n",
    "- `Historical Data` -> `Model` : **Batch training**\n",
    "- `Live Data` -> `Model` <-> `Info & recommendations` : **Real-time predictions**\n",
    "- **Feedback** from Real-time predictions to Batch training\n",
    "- `Historical Data` -> `Model2`\n",
    "\n",
    "**Key questions in Managing models**\n",
    "- When to update a model?\n",
    "- How to choose between existing models?\n",
    "- Answer: continuous evaluation and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is evaluation?\n",
    "- Evaluation = Predictions + Metric\n",
    "\n",
    "**Evaluating a recommender**\n",
    "- `Sum squared error` in Batch training part\n",
    " - Offline evaluation: When to update model\n",
    "- `User engagement` in Real-time predictions part ( in production )\n",
    " - Online evaluation: Choosing between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating ML models\n",
    "- Why update?\n",
    " - Trends and user tastes change over time\n",
    " - Model performance drops\n",
    "- When to update?\n",
    " - Track statistics of data over time\n",
    " - Monitor both offline & online metrics\n",
    " - Update when offline metric diverges from online metrics or not achieving desired targets\n",
    "\n",
    "**A/B Testing in online: Choosing between ML models**\n",
    "- Model 1 -> Group A ( 2000 visits, 10% CTR )\n",
    "- Model 2 -> Group B ( 2000 visits, 30% CTR ) -> Everybody gets Model 2\n",
    "\n",
    "**Other productions considerations**\n",
    "- A/B testing caveats\n",
    " - Also multi-armed bandits\n",
    "- Versioning\n",
    "- Provenance\n",
    "- Dashboards\n",
    "- Reports\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning challenges\n",
    "\n",
    "- Model selection\n",
    "- Feature engineering/representation\n",
    " - Bag of word raw counts?\n",
    " - Normalize?\n",
    " - tf-dif?\n",
    " - Bigrams\n",
    " - Trigrams\n",
    " - ...\n",
    "- Scaling\n",
    " - Concurrently, Data is getting big...\n",
    " - Many source of data\n",
    "- CPUs stopped getting faster\n",
    " - ML in the context of parallel architectures\n",
    " - But scalable ML in theses systems is **hard**, especially in terms of:\n",
    "   - Programmability\n",
    "   - Data distribution\n",
    "   - Failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
