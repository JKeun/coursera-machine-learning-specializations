{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1\n",
    "\n",
    "---\n",
    "### 1. Why you should learn machine learning with us\n",
    "\n",
    "### Old view of ML\n",
    "Data -> ML Algorithm -> My curve is better -> Write a paper\n",
    "\n",
    "### Intelligent Applications using ML\n",
    "- Amazon -> Recommendation in Website\n",
    "- Google -> Retargeting\n",
    "- Netflix -> Recommender System\n",
    "- Pandora -> Recommedation of Music\n",
    "- Facebook, Uber -> Connect People\n",
    "\n",
    "### The machine learning pipeline\n",
    "Data -> ML Method -> Intelligence\n",
    "\n",
    "### Case Studies\n",
    "1. Regression -> Predicting house prices\n",
    "2. Classification -> Sentiment analysis\n",
    "3. Clustering -> Document retrieval\n",
    "4. Matrix Factorization -> Product recommendation\n",
    "5. Deep learning -> Visual product recommender\n",
    "\n",
    "### Overview\n",
    "- Frist course is about building, evaludating and deploying intelligence in each case study\n",
    "- Subsequent courses provide depth in **models & algorithms**, but still use case studies\n",
    "\t- Regression\n",
    "\t- Classification\n",
    "\t- Clustering & Retrieval\n",
    "\t- Matrix Factorization & Demensionality Reduction\n",
    "\t- Capstone: Build an Intelligent Application with Deep Learning\n",
    "\n",
    "---\n",
    "### 2. Regression\n",
    "- Models\n",
    "\t- Linear regression\n",
    "\t- Regularization: Ridge(L2), Lasso(L1)\n",
    "- Algorithms\n",
    "\t- Gradient descent\n",
    "\t- Coordinate descent\n",
    "- Concepts\n",
    "\t- Loss functions, bias-variance tradeoff, cross-validation, sparsity, overfitting, model selection\n",
    "\n",
    "---\n",
    "### 3. Classification\n",
    "- Models\n",
    "\t- Linear classifiers (logistic regression, SVMs, perceptron)\n",
    "\t- Kernels\n",
    "\t- Decision trees\n",
    "- Algoritms\n",
    "\t- Stochastic gradient descent\n",
    "\t- Boosting\n",
    "- Concepts\n",
    "\t- Decision boundaries, MLE, ensemble methods, random forests, CART, online learning\n",
    "\n",
    "---\n",
    "### 4. Clustering & Retrieval\n",
    "- Models\n",
    "\t- Nearest neigbors\n",
    "\t- Clustering, mixtures of Gaussians\n",
    "\t- Latent Dirichlet allocation (LDA)\n",
    "- Algoritms\n",
    "\t- KD-trees, locality-sensitive hashing (LSH)\n",
    "\t- K-means\n",
    "\t- Expectation0maximization (EM)\n",
    "- Concepts\n",
    "\t- Distance metrics, approximation algorithms, hashing, sampling algorithms, scaling up with map-reduce\n",
    "\n",
    "---\n",
    "### 5. Matrix Factorization & Dimensionality Reduction\n",
    "- Models\n",
    "\t- Collaborative filtering\n",
    "\t- Matrix factorization\n",
    "\t- PCA\n",
    "- Algoritms\n",
    "\t- Coordinate descent\n",
    "\t- Eigen decomposition\n",
    "\t- SVD\n",
    "- Concepts\n",
    "\t- Matrix completion, eigenvalues, random projections, cold-start problem, diversity, scaling up\n",
    "\n",
    "---\n",
    "### 6. Capstone: An intelligent application using deep learning\n",
    "- Build & deploy a recommender using product images and text sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
